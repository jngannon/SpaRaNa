{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build and train a simple model\n",
    "\n",
    "This is a notebook that builds and trains a simple model as an example of how to use Sparana. It uses ReLu activations with a linear final layer, Xavier initialization and the Adam optimizer. The layers, initialization and optimizer are interchangable with some other types in the library. You will need MNIST pickle files to run this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initalizing GPU weights\n"
     ]
    }
   ],
   "source": [
    "# Numpy and cupy are imported, because I use them in all of my experiments, you don't need them to run these cells\n",
    "import numpy as np\n",
    "import cupy as cp\n",
    "\n",
    "# This is needed to load the MNIST files for training and testing\n",
    "import pickle\n",
    "\n",
    "# These are the Sparana objects needed to build a model\n",
    "from sparana.model import model\n",
    "from sparana.layers import full_relu_layer\n",
    "from sparana.layers import full_linear_layer\n",
    "# This is the optimizer used to train the model\n",
    "from sparana.optimizer import adam_optimizer\n",
    "# Load the data into this object, which will return optimized minibatches, and track how many minibatches/epochs \n",
    "# batches have been loaded\n",
    "from sparana.data_loader import loader\n",
    "\n",
    "# This is not needed to train and test a simple model, but I am going to demonstrate it here too\n",
    "from sparana.saver import model_saver\n",
    "# Put your own path in here\n",
    "path = 'path'\n",
    "\n",
    "# This initializes the model object, the 2 things that are required are the input size, and a list of layer objects.\n",
    "mymodel = model(input_size = 784, \n",
    "                # These are the layers input as a list, the final layer size is the number of classes the model will have.\n",
    "                layers = [full_relu_layer(size = 1000), \n",
    "                          full_relu_layer(size = 800),\n",
    "                          full_relu_layer(size = 400),\n",
    "                          full_linear_layer(size = 10)],\n",
    "                # This is set automatically, but I keep it in here as a demonstration\n",
    "                comp_type = 'GPU')\n",
    "\n",
    "# Initialize the weights here, after this randomly generated matrices are now in the GPU memory\n",
    "mymodel.initialize_weights('Xavier', bias_constant = 0.1)\n",
    "\n",
    "# Initialize the Adam optimizer, the associated matrices are now in GPU memory\n",
    "opt = adam_optimizer(mymodel, 0.0001, epsilon = 0.001)\n",
    "\n",
    "#Initialize the saver\n",
    "mysaver = model_saver(mymodel)\n",
    "\n",
    "# Initialize the loader object and load the MNIST dataset from pickle files using pickle\n",
    "myloader = loader(pickle.load(open('MNIST_train_images.p', 'rb')),\n",
    "                 pickle.load(open('MNIST_train_labels.p', 'rb')),\n",
    "                 pickle.load(open('MNIST_test_images.p', 'rb')),\n",
    "                 pickle.load(open('MNIST_test_labels.p', 'rb')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "This cell just trains, then stores the model on RAM. The saver object can save the model to the hard disk with the line:\n",
    "```python\n",
    "mysaver.pickle_model('filename.p')\n",
    "```\n",
    "Demonstrated in the Demo-Lobotomizer notebook where I have a practical reason to do that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9848\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(20000):\n",
    "    images, labels = myloader.minibatch(250)\n",
    "    opt.train_step(images, labels)    \n",
    "\n",
    "print(mymodel.get_accuracy(myloader.test_data(), myloader.test_labels()))\n",
    "\n",
    "mysaver.store_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outputs\n",
    "\n",
    "Just a couple of lines here displaying outputs of the model class. I am looking at 10 datapoints from the training set. The outputs will look the same as test set outputs, and will not clutter up your screen. \n",
    "\n",
    "Quick not here, I am using a linear final layer here, so all of the output values should be either very close to 1 or very close to 0, they do not sum to 1 like they would for a softmax layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model outputs\n",
      "[[ 2.4904758e-03 -2.0734221e-04  1.1540107e-02  1.2681112e-02\n",
      "   7.2287992e-03  9.5505381e-01 -6.8125054e-03 -4.9916729e-03\n",
      "   4.7410429e-03  9.7680464e-03]\n",
      " [ 5.1029474e-03  5.8564320e-03 -1.1851490e-02  1.0037068e+00\n",
      "  -4.2976886e-03 -1.1061430e-02 -6.3339844e-03  1.5931986e-02\n",
      "   1.2010679e-02 -1.2753904e-04]\n",
      " [-3.2111704e-03 -1.6523011e-02 -5.8771968e-03 -4.6210736e-03\n",
      "   1.0040379e+00  3.1093508e-04  1.7267548e-02 -1.7646253e-03\n",
      "   9.5325261e-03  6.2608197e-03]\n",
      " [ 1.2597173e-02 -1.2377575e-03  9.4277769e-01  6.8120211e-03\n",
      "   1.7710321e-02 -8.4303766e-03  1.0956816e-02  1.3016492e-02\n",
      "   1.1184365e-02 -6.4533129e-03]\n",
      " [ 1.0178781e+00 -2.9369667e-03 -5.4296926e-03 -6.4956993e-03\n",
      "   5.1478297e-04  2.5436655e-03  6.5911636e-03 -9.3612894e-03\n",
      "  -1.3830140e-03 -2.1958500e-03]\n",
      " [ 9.1752037e-03  9.4192761e-01  2.3422047e-02  2.3322269e-02\n",
      "  -1.9607097e-03 -6.2354058e-03  7.9550743e-03  1.1833869e-02\n",
      "  -5.9905648e-04 -3.2844469e-03]\n",
      " [ 2.9499829e-03  1.0000089e+00 -1.3918504e-02  1.0232642e-02\n",
      "   4.3697208e-03 -5.6172907e-04  4.8744604e-03 -6.2131882e-04\n",
      "   1.5435830e-02 -3.3628345e-03]\n",
      " [-1.3443738e-02  6.3948333e-04 -1.0122962e-02  4.1544437e-03\n",
      "  -6.0512125e-03 -1.2482591e-02  6.6325068e-05  9.2786029e-03\n",
      "   1.0305866e+00 -6.0107559e-04]\n",
      " [ 7.7807233e-03  9.7956687e-01 -1.3946071e-03 -7.3432922e-04\n",
      "   6.7103878e-03  5.3828135e-03  7.6581612e-03 -4.0126443e-03\n",
      "   1.7977208e-03  9.7765028e-04]\n",
      " [ 1.0026814e+00 -5.9271082e-03 -3.4821555e-03  1.8806376e-02\n",
      "   1.6739368e-03  1.3014503e-02 -2.3372397e-03  1.1825845e-02\n",
      "   2.6801676e-03 -4.2951852e-04]]\n",
      "Argmax of model outputs\n",
      "[5 3 4 2 0 1 1 8 1 0]\n",
      "Labels\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "Accuracy\n",
      "0.9848\n"
     ]
    }
   ],
   "source": [
    "images, labels = myloader.minibatch(10)\n",
    "\n",
    "outputs = mymodel.outputs(images)\n",
    "\n",
    "print('Model outputs')\n",
    "print(outputs)\n",
    "\n",
    "# I didn't put this in the library, it's only 1 line, didn't seem necessary\n",
    "\n",
    "one_hot = np.argmax(outputs, axis = 1)\n",
    "\n",
    "print('Argmax of model outputs')\n",
    "print(one_hot)\n",
    "\n",
    "#We can compare this to the correct classes, the labels\n",
    "\n",
    "print('Labels')\n",
    "print(labels)\n",
    "\n",
    "# I hope these are all correct, won't look good if they are wrong ¯\\_(ツ)_/¯\n",
    "\n",
    "# Or I can just get the accuracy calling get_accuracy from the model object, with the test set\n",
    "\n",
    "accuracy = mymodel.get_accuracy(myloader.test_data(), myloader.test_labels())\n",
    "\n",
    "print('Accuracy')\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
